{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model.net\n",
    "본 노트에서는 `model.ops.ipynb` 노트에서 구현한 `MultiChannelEmbedding`, `ConvolutionLayer`, `MaxOverTimepooling` class를 활용하여, [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882)에서 제시하고 있는 전체 구조를 `SenCNN` class로 구현합니다.\n",
    "\n",
    "![Alt text](https://raw.githubusercontent.com/aisolab/strnlp/master/materials/img/sencnn_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model.ops import MultiChannelEmbedding, ConvolutionLayer, MaxOverTimePooling\n",
    "from model.utils import Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation tips\n",
    "**전체 구조를 구현하는 방법은 연산을 구현할 때와 마찬가지로 예제데이터를 미리 생각해놓고 확인하면서 구현하는 것입니다.** 구현해놓은 연산관련 코드들을 기반으로  전체 구조를 구현할 때 가장 간단한 미니배치(eg. 미니배치 사이즈가 2인 경우)를 상정하고 구현합니다. 이를 위해서 `model.ops.ipynb` 노트에서 활용했던 코드들을 가져와서 가장 간단한 미니배치를 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/root/Documents/archive/strnlp/exercise/data/.DS_Store'),\n",
      " PosixPath('/root/Documents/archive/strnlp/exercise/data/train.txt'),\n",
      " PosixPath('/root/Documents/archive/strnlp/exercise/data/morphs_vec.pkl'),\n",
      " PosixPath('/root/Documents/archive/strnlp/exercise/data/validation.txt'),\n",
      " PosixPath('/root/Documents/archive/strnlp/exercise/data/tokenizer.pkl'),\n",
      " PosixPath('/root/Documents/archive/strnlp/exercise/data/test.txt'),\n",
      " PosixPath('/root/Documents/archive/strnlp/exercise/data/vocab.pkl')]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from mecab import MeCab\n",
    "from torch.utils.data import DataLoader\n",
    "from model.data import Corpus\n",
    "from model.utils import Vocab, Tokenizer, PadSequence\n",
    "\n",
    "data_dir = Path.cwd() / 'data'\n",
    "list_of_dataset = list(data_dir.iterdir())\n",
    "pprint(list_of_dataset)\n",
    "with open(list_of_dataset[-1], mode='rb') as io:\n",
    "    vocab = pickle.load(io)\n",
    "\n",
    "pad_sequence = PadSequence(length=32, pad_val=vocab.to_indices(vocab.padding_token))\n",
    "split_morphs = MeCab().morphs\n",
    "tokenizer = Tokenizer(vocab, split_fn=split_morphs, pad_fn=pad_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_corpus = Corpus(list_of_dataset[1], transform_fn=tokenizer.split_and_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataLoader` class의 instance를 이용, 가장 간단한 미니배치 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dl = DataLoader(tr_corpus, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[7270, 2086, 8244, 1953,   46,   66, 3289, 2424,  471, 1953, 2455, 2952,\n",
      "         2251, 3231, 1916,   46,   46,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [1111, 6491,    0,    0, 7593,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]]), tensor([0, 1])]\n",
      "tensor([[7270, 2086, 8244, 1953,   46,   66, 3289, 2424,  471, 1953, 2455, 2952,\n",
      "         2251, 3231, 1916,   46,   46,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [1111, 6491,    0,    0, 7593,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]]) tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "mb = next(iter(tr_dl))\n",
    "x_mb, y_mb = mb\n",
    "\n",
    "print(mb)\n",
    "print(x_mb, y_mb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SenCNN` class 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model.ops import MultiChannelEmbedding, ConvolutionLayer, MaxOverTimePooling\n",
    "from model.utils import Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `SenCNN` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiChannelEmbedding, ConvolutionLayer, MaxOverTimepooling, nn.Dropout, nn.Linear를 이용하여 직접 구현해보세요.\n",
    "# https://github.com/aisolab/strnlp/blob/master/exercise/model/net.py\n",
    "class SenCNN(nn.Module):\n",
    "    \"\"\"SenCNN class\"\"\"\n",
    "    def __init__(self, num_classes: int, vocab: Vocab) -> None:\n",
    "        \"\"\"Instantiating SenCNN class\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): the number of classes\n",
    "            vocab (model.utils.Vocab): the instance of model.utils.Vocab\n",
    "        \"\"\"\n",
    "        super(SenCNN, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SenCNN(num_classes=2, vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3085, 0.0949],\n",
      "        [0.2435, 0.0354]], grad_fn=<AddmmBackward>) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "yhat = model(x_mb)\n",
    "print(yhat, yhat.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
